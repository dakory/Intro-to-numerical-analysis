{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple iteration for systems of linear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate a random diagonally dominant matrix, for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rndm = np.random.RandomState(1234)\n",
    "\n",
    "n = 10\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
    "b = rndm.uniform(size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I.  Jacobi iteration\n",
    "\n",
    "Given\n",
    "\n",
    "$$\n",
    "A x = b\n",
    "$$\n",
    "\n",
    "separate the diagonal part $D$,\n",
    "\n",
    "$$ A = D + (A - D) $$\n",
    "\n",
    "and write\n",
    "\n",
    "$$\n",
    "x = D^{-1} (D - A) x + D^{-1} b\\;.\n",
    "$$\n",
    "\n",
    "Then iterate\n",
    "\n",
    "$$\n",
    "x_{n + 1} = B x_{n} + c\\;,\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "B = D^{-1} (A - D) \\qquad \\text{and} \\qquad c = D^{-1} b\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the matrix and the r.h.s. for the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_1d = np.diag(A)\n",
    "\n",
    "B = -A.copy()\n",
    "np.fill_diagonal(B, 0)\n",
    "\n",
    "D = np.diag(diag_1d)\n",
    "invD = np.diag(1./diag_1d)\n",
    "BB = invD @ B \n",
    "c = invD @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "assert_allclose(-B + D, A)\n",
    "\n",
    "\n",
    "# xx is a \"ground truth\" solution, compute it using a direct method\n",
    "xx = np.linalg.solve(A, b)\n",
    "\n",
    "np.testing.assert_allclose(A@xx, b)\n",
    "np.testing.assert_allclose(D@xx, B@xx + b)\n",
    "np.testing.assert_allclose(xx, BB@xx + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that $\\| B\\| \\leqslant 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03919429,  0.03780037,  0.04283232,  0.02365951,  0.05745031,\n",
       "       -0.00030244, -0.00577279,  0.03177549, -0.00422849,  0.05284648])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(BB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 50\n",
    "\n",
    "x0 = np.ones(n)\n",
    "x = x0\n",
    "for _ in range(n_iter):\n",
    "    x = BB @ x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.11022302e-16,  0.00000000e+00, -2.22044605e-16, -1.11022302e-16,\n",
       "        1.11022302e-16,  0.00000000e+00, -2.08166817e-17,  0.00000000e+00,\n",
       "       -2.77555756e-17,  1.11022302e-16])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result:\n",
    "\n",
    "A @ x - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task I.1\n",
    "\n",
    "Collect the proof-of-concept above into a single function implementing the Jacobi iteration. This function should receive the r.h.s. matrix $A$, the l.h.s. vector `b`, and the number of iterations to perform.\n",
    "\n",
    "\n",
    "The matrix $A$ in the illustration above is strongly diagonally dominant, by construction. \n",
    "What happens if the diagonal matrix elements of $A$ are made smaller? Check the convergence of the Jacobi iteration, and check the value of the norm of $B$.\n",
    "\n",
    "(20% of the total grade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]: 3.5523472974221173\n",
      "[2]: 1.0583434151820499\n",
      "[3]: 0.3176659062459442\n",
      "[4]: 0.09527139039266808\n",
      "[5]: 0.02857131901060047\n",
      "[6]: 0.008568765713162348\n",
      "[7]: 0.002569809967278823\n",
      "[8]: 0.0007706987060726627\n",
      "[9]: 0.00023113629018306007\n",
      "[10]: 6.931890107053155e-05\n",
      "[11]: 2.0789076142311084e-05\n",
      "[12]: 6.2347452758258756e-06\n",
      "[13]: 1.8698304952224216e-06\n",
      "[14]: 5.607712790907382e-07\n",
      "[15]: 1.681780398082866e-07\n",
      "[16]: 5.043741384477829e-08\n",
      "[17]: 1.5126426232761613e-08\n",
      "[18]: 4.536488949075102e-09\n",
      "[19]: 1.3605151095996693e-09\n",
      "[20]: 4.0802512861481953e-10\n",
      "[21]: 1.223687273038676e-10\n",
      "[22]: 3.6698998007178574e-11\n",
      "[23]: 1.1006194913787404e-11\n",
      "[24]: 3.3008352995356205e-12\n",
      "[25]: 9.899265435153738e-13\n",
      "[26]: 2.96863228443911e-13\n",
      "[27]: 8.904717241353665e-14\n",
      "[28]: 2.6701557631625405e-14\n",
      "[29]: 7.993605777301127e-15\n",
      "[30]: 2.416122857340497e-15\n",
      "[31]: 6.845218836204481e-16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "def Jacobi_iterate(A: np.array, b: np.array, eps=1e-15, n_max_iters=1000):\n",
    "    \"\"\"\n",
    "        Arguments:\n",
    "            A (np.array): initial A matrix\n",
    "            b (np.array): initial array\n",
    "            eps (float): minimal error value\n",
    "            n_max_iter (int): maximum amount of iterations need to be done\n",
    "            \n",
    "        Outputs:\n",
    "            n_iter (int): amount of iterations done\n",
    "            x (np.array): vector\n",
    "    \"\"\"\n",
    "    # 1. Matrix splitting\n",
    "    D, U, L = np.diag(np.diag(A)), np.triu(A, 1), np.tril(A, -1)\n",
    "\n",
    "    # 2. Building an inverse matrix\n",
    "    D_inv = np.linalg.inv(D)\n",
    "\n",
    "    # 3. Defining objective function\n",
    "    objective = lambda A, x, b: mean_absolute_error(A @ x, b)\n",
    "    \n",
    "    # 4. Initialization of starting x\n",
    "    x_prev = np.zeros(shape=(A.shape[0]))\n",
    "    x = np.random.uniform(size=(A.shape[0]))\n",
    "\n",
    "    # 5. Computing optimization by precomputed components\n",
    "    x_multiplier = D_inv @ (-L - U)\n",
    "    offset = D_inv @ b\n",
    "    \n",
    "    # 6. Start iteratingter = 0\n",
    "    n_iter = 0\n",
    "    while objective(A, x, b) > eps and n_iter < n_max_iters:\n",
    "        x_prev = x\n",
    "        x = x_multiplier @ x + offset\n",
    "        n_iter += 1\n",
    "        print(f\"[{n_iter}]: {objective(A, x, b)}\")\n",
    "        \n",
    "    return n_iter, x\n",
    "\n",
    "_, x = Jacobi_iterate(A, b, n_max_iters = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Verficiation of convergence to actual X\n",
    "np.allclose(A @ x, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76711663, 0.70811536, 0.79686718, 0.55776083, 0.96583653,\n",
       "       0.1471569 , 0.029647  , 0.59389349, 0.1140657 , 0.95080985])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Seidel's iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task II.1\n",
    "\n",
    "Implement the Seidel's iteration. \n",
    "\n",
    "Test it on a random matrix. Study the convergence of iterations, relate to the norm of the iteration matrix.\n",
    "\n",
    "(30% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ... ENTER YOUR CODE HERE ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Minimum residual scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task III.1\n",
    "\n",
    "Implement the $\\textit{minimum residual}$ scheme: an explicit non-stationary method, where at each step you select the iteration parameter $\\tau_n$ to minimize the residual $\\mathbf{r}_{n+1}$ given $\\mathbf{r}_n$. Test it on a random matrix, study the convergence to the solution, in terms of the norm of the residual and the deviation from the ground truth solution (which you can obtain using a direct method). Study how the iteration parameter $\\tau_n$ changes as iterations progress.\n",
    "\n",
    "(50% of the grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ... ENTER YOUR CODE HERE ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
